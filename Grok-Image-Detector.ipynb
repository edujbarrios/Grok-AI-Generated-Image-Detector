{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Detecting AI-Generated Images by Grok\n\n", "This Jupyter Notebook is designed to classify images as either real or generated by Grok's AI tools. ", "It uses a convolutional neural network (CNN) implemented in PyTorch for the detection.\n\n", "### Author: Eduardo Jos\u00e9 Barrios Garc\u00eda"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Import Necessary Libraries\n", "In this section, we import all the required libraries for data processing, model construction, and evaluation."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch\n", "import torch.nn as nn\n", "import torch.optim as optim\n", "from torchvision import datasets, transforms\n", "from torch.utils.data import DataLoader, Dataset\n", "import cv2\n", "import os\n", "import numpy as np\n", "import matplotlib.pyplot as plt"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Preprocessing Function\n", "Defines the preprocessing pipeline to convert images to grayscale, detect edges, and resize them for model input."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def preprocess_image(image):\n", "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n", "    edges = cv2.Canny(gray, 50, 150)\n", "    resized = cv2.resize(edges, (128, 128))\n", "    return resized"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Custom Dataset Class\n", "A dataset class for loading and preprocessing images with corresponding labels."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class CustomImageDataset(Dataset):\n", "    def __init__(self, directory, label, transform=None):\n", "        self.directory = directory\n", "        self.label = label\n", "        self.transform = transform\n", "        self.image_files = os.listdir(directory)\n", "\n", "    def __len__(self):\n", "        return len(self.image_files)\n", "\n", "    def __getitem__(self, idx):\n", "        filepath = os.path.join(self.directory, self.image_files[idx])\n", "        try:\n", "            img = cv2.imread(filepath)\n", "            preprocessed_img = preprocess_image(img)\n", "            img_tensor = torch.tensor(preprocessed_img, dtype=torch.float32).unsqueeze(0) / 255.0\n", "            label_tensor = torch.tensor(self.label, dtype=torch.float32)\n", "            return img_tensor, label_tensor\n", "        except Exception as e:\n", "            print(f\"Error loading image {self.image_files[idx]}: {e}\")\n", "            return None, None"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Define the CNN Model\n", "The CNN architecture is defined here, optimized for detecting the Grok logo in images."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class LogoDetector(nn.Module):\n", "    def __init__(self):\n", "        super(LogoDetector, self).__init__()\n", "        self.conv_layers = nn.Sequential(\n", "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n", "            nn.ReLU(),\n", "            nn.MaxPool2d(kernel_size=2, stride=2),\n", "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n", "            nn.ReLU(),\n", "            nn.MaxPool2d(kernel_size=2, stride=2)\n", "        )\n", "        self.fc_layers = nn.Sequential(\n", "            nn.Flatten(),\n", "            nn.Linear(64 * 32 * 32, 128),\n", "            nn.ReLU(),\n", "            nn.Linear(128, 1),\n", "            nn.Sigmoid()\n", "        )\n", "\n", "    def forward(self, x):\n", "        x = self.conv_layers(x)\n", "        x = self.fc_layers(x)\n", "        return x"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Dataset Configuration\n", "Load images from directories, split them into training and testing datasets, and prepare DataLoader objects."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["real_images_dir = \"dataset/real_images\"\n", "generated_images_dir = \"dataset/generated_images\"\n", "\n", "real_dataset = CustomImageDataset(real_images_dir, label=0)\n", "generated_dataset = CustomImageDataset(generated_images_dir, label=1)\n", "\n", "data = real_dataset + generated_dataset\n", "train_size = int(0.8 * len(data))\n", "test_size = len(data) - train_size\n", "train_dataset, test_dataset = torch.utils.data.random_split(data, [train_size, test_size])\n", "\n", "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n", "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Train the Model\n", "This function trains the model using the training dataset and evaluates the loss after each epoch."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model = LogoDetector()\n", "criterion = nn.BCELoss()\n", "optimizer = optim.Adam(model.parameters(), lr=0.001)\n", "\n", "def train_model(model, train_loader, criterion, optimizer, epochs=10):\n", "    model.train()\n", "    for epoch in range(epochs):\n", "        epoch_loss = 0\n", "        for images, labels in train_loader:\n", "            optimizer.zero_grad()\n", "            outputs = model(images)\n", "            loss = criterion(outputs.squeeze(), labels)\n", "            loss.backward()\n", "            optimizer.step()\n", "            epoch_loss += loss.item()\n", "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss / len(train_loader)}\")\n", "\n", "train_model(model, train_loader, criterion, optimizer)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Evaluate the Model\n", "Evaluate the trained model on the test dataset and calculate accuracy."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def evaluate_model(model, test_loader):\n", "    model.eval()\n", "    correct = 0\n", "    total = 0\n", "    with torch.no_grad():\n", "        for images, labels in test_loader:\n", "            outputs = model(images)\n", "            predicted = (outputs.squeeze() > 0.5).float()\n", "            total += labels.size(0)\n", "            correct += (predicted == labels).sum().item()\n", "    print(f\"Accuracy: {100 * correct / total}%\")\n", "\n", "evaluate_model(model, test_loader)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Save and Predict\n", "Save the trained model and use it for predicting new images."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["torch.save(model.state_dict(), \"grok_detector_model.pth\")\n", "\n", "def predict_image(image_path, model):\n", "    model.eval()\n", "    img = cv2.imread(image_path)\n", "    preprocessed_img = preprocess_image(img)\n", "    img_tensor = torch.tensor(preprocessed_img, dtype=torch.float32).unsqueeze(0).unsqueeze(0) / 255.0\n", "    with torch.no_grad():\n", "        prediction = model(img_tensor)\n", "        return \"Generated by AI (Grok)\" if prediction.item() > 0.5 else \"Real Image\"\n", "\n", "model.load_state_dict(torch.load(\"grok_detector_model.pth\"))\n", "image_path = \"test_image.jpg\"\n", "prediction = predict_image(image_path, model)\n", "print(f\"Prediction for {image_path}: {prediction}\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.10"}}, "nbformat": 4, "nbformat_minor": 2}